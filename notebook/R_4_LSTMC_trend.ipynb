{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "py_file_location = '../PrivatePackages'\n",
    "sys.path.append(os.path.abspath(py_file_location))\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import JiaoCheng\n",
    "import NingXiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'trend'\n",
    "MODEL = 'lstmc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_data = pd.read_csv('../data/curated_data.csv')\n",
    "curated_data = curated_data[['date', \n",
    "                        'stock',\n",
    "                        'trend',\n",
    "                        'closePrice_lag_1', \n",
    "                        'log_ret_normalised_by_day_lag_1', \n",
    "                        'closePriceNorm_lag_1', \n",
    "                        'log_ret_lag_1', \n",
    "                        'mean_log_ret_lag_1',\n",
    "                        'mean_closePrice_lag_1',\n",
    "                        'mean_closePriceNorm_lag_1',\n",
    "                        'mean_log_ret_normalised_by_day_lag_1', \n",
    "                        'pos_log_ret_lag_1',\n",
    "                        'pos_closePrice_lag_1',\n",
    "                        'pos_closePriceNorm_lag_1',\n",
    "                        'pos_log_ret_normalised_by_day_lag_1']]\n",
    "curated_data['date'] = pd.to_datetime(curated_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [datetime.datetime(year=2022, month=12, day = 31) + datetime.timedelta(days=i) for i in range(250)]\n",
    "val_date_start = date[175]\n",
    "test_date_start = date[175+38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_data['date'] = pd.to_datetime(curated_data['date'])\n",
    "curated_data = curated_data.dropna()\n",
    "\n",
    "train = curated_data[(curated_data['date'] < val_date_start)]\n",
    "val = curated_data[(curated_data['date'] < test_date_start) & (curated_data['date'] >= val_date_start)]\n",
    "test = curated_data[(curated_data['date'] >= test_date_start)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_factory(data, lag):\n",
    "    x_list, y_list = list(), list()\n",
    "\n",
    "    for id, stock_data in data.groupby('stock'):\n",
    "        stock_data.sort_values(by='date', inplace=True)\n",
    "        stock_data.drop(['stock', 'date'], axis=1, inplace=True)\n",
    "        stock_data.index = range(len(stock_data))\n",
    "\n",
    "        for i in range(len(stock_data)):\n",
    "            \n",
    "            if i < lag-1:\n",
    "                continue\n",
    "\n",
    "            x = stock_data.iloc[i-lag+1:i+1].values.copy()\n",
    "            x[-1:, 0] = 0 # mask last day's return\n",
    "            y = stock_data.loc[i]['trend']\n",
    "            \n",
    "            x_list.append(x)\n",
    "            y_list.append(y)\n",
    "    \n",
    "    return x_list, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAG = 5\n",
    "\n",
    "train_x, train_y = data_factory(train, LAG)\n",
    "val_x, val_y = data_factory(val, LAG)\n",
    "test_x, test_y = data_factory(test, LAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JiaoCheng Initialised\n",
      "Successfully read in model <class 'models.LSTM.LSTMC_pt'>, which is a Classification model\n",
      "Read in Train X data\n",
      "Read in Train y data\n",
      "Read in Val X data\n",
      "Read in Val y data\n",
      "Read in Test X data\n",
      "Read in Test y data\n",
      "Successfully recorded hyperparameter choices\n",
      "Successfully recorded non_tuneable_hyperparameter choices\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (0, lstm_hidden_layer_n_neurons              6.0\n",
      "lstm_n_hidden_layers                     1.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          1.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons             6.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.502249\n",
      "Val accu                            0.502353\n",
      "Test accu                           0.490909\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.335835\n",
      "Val f1                              0.335951\n",
      "Test f1                             0.323282\n",
      "Train precision                     0.252254\n",
      "Val precision                       0.252358\n",
      "Test precision                      0.240992\n",
      "Train recall                        0.502249\n",
      "Val recall                          0.502353\n",
      "Test recall                         0.490909\n",
      "Time                                  225.86\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 0, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (1, lstm_hidden_layer_n_neurons              6.0\n",
      "lstm_n_hidden_layers                     2.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          1.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons             6.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.502249\n",
      "Val accu                            0.502353\n",
      "Test accu                           0.490909\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.335835\n",
      "Val f1                              0.335951\n",
      "Test f1                             0.323282\n",
      "Train precision                     0.252254\n",
      "Val precision                       0.252358\n",
      "Test precision                      0.240992\n",
      "Train recall                        0.502249\n",
      "Val recall                          0.502353\n",
      "Test recall                         0.490909\n",
      "Time                                  282.84\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 1, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (2, lstm_hidden_layer_n_neurons              6.0\n",
      "lstm_n_hidden_layers                     3.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          1.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons             6.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.497751\n",
      "Val accu                            0.497647\n",
      "Test accu                           0.509091\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.330838\n",
      "Val f1                              0.330722\n",
      "Test f1                             0.343483\n",
      "Train precision                     0.247757\n",
      "Val precision                       0.247653\n",
      "Test precision                      0.259174\n",
      "Train recall                        0.497751\n",
      "Val recall                          0.497647\n",
      "Test recall                         0.509091\n",
      "Time                                  296.26\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 2, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (3, lstm_hidden_layer_n_neurons              6.0\n",
      "lstm_n_hidden_layers                     1.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          2.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons             6.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.502249\n",
      "Val accu                            0.502353\n",
      "Test accu                           0.490909\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.335835\n",
      "Val f1                              0.335951\n",
      "Test f1                             0.323282\n",
      "Train precision                     0.252254\n",
      "Val precision                       0.252358\n",
      "Test precision                      0.240992\n",
      "Train recall                        0.502249\n",
      "Val recall                          0.502353\n",
      "Test recall                         0.490909\n",
      "Time                                  220.17\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 3, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (4, lstm_hidden_layer_n_neurons              6.0\n",
      "lstm_n_hidden_layers                     1.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          3.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons             6.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.497751\n",
      "Val accu                            0.497647\n",
      "Test accu                           0.509091\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.330838\n",
      "Val f1                              0.330722\n",
      "Test f1                             0.343483\n",
      "Train precision                     0.247757\n",
      "Val precision                       0.247653\n",
      "Test precision                      0.259174\n",
      "Train recall                        0.497751\n",
      "Val recall                          0.497647\n",
      "Test recall                         0.509091\n",
      "Time                                   223.3\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 4, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (5, lstm_hidden_layer_n_neurons             12.0\n",
      "lstm_n_hidden_layers                     1.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          1.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons             6.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.502249\n",
      "Val accu                            0.502353\n",
      "Test accu                           0.490909\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.335835\n",
      "Val f1                              0.335951\n",
      "Test f1                             0.323282\n",
      "Train precision                     0.252254\n",
      "Val precision                       0.252358\n",
      "Test precision                      0.240992\n",
      "Train recall                        0.502249\n",
      "Val recall                          0.502353\n",
      "Test recall                         0.490909\n",
      "Time                                  219.51\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 5, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (6, lstm_hidden_layer_n_neurons             25.0\n",
      "lstm_n_hidden_layers                     1.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          1.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons             6.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.502249\n",
      "Val accu                            0.502353\n",
      "Test accu                           0.490909\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.335835\n",
      "Val f1                              0.335951\n",
      "Test f1                             0.323282\n",
      "Train precision                     0.252254\n",
      "Val precision                       0.252358\n",
      "Test precision                      0.240992\n",
      "Train recall                        0.502249\n",
      "Val recall                          0.502353\n",
      "Test recall                         0.490909\n",
      "Time                                  244.98\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 6, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (7, lstm_hidden_layer_n_neurons             50.0\n",
      "lstm_n_hidden_layers                     1.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          1.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons             6.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.497751\n",
      "Val accu                            0.497647\n",
      "Test accu                           0.509091\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.330838\n",
      "Val f1                              0.330722\n",
      "Test f1                             0.343483\n",
      "Train precision                     0.247757\n",
      "Val precision                       0.247653\n",
      "Test precision                      0.259174\n",
      "Train recall                        0.497751\n",
      "Val recall                          0.497647\n",
      "Test recall                         0.509091\n",
      "Time                                  276.16\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 7, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (8, lstm_hidden_layer_n_neurons            100.0\n",
      "lstm_n_hidden_layers                     1.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          1.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons             6.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.497751\n",
      "Val accu                            0.497647\n",
      "Test accu                           0.509091\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.330838\n",
      "Val f1                              0.330722\n",
      "Test f1                             0.343483\n",
      "Train precision                     0.247757\n",
      "Val precision                       0.247653\n",
      "Test precision                      0.259174\n",
      "Train recall                        0.497751\n",
      "Val recall                          0.497647\n",
      "Test recall                         0.509091\n",
      "Time                                  356.66\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 8, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (9, lstm_hidden_layer_n_neurons              6.0\n",
      "lstm_n_hidden_layers                     1.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          1.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons            12.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.497751\n",
      "Val accu                            0.497647\n",
      "Test accu                           0.509091\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.330838\n",
      "Val f1                              0.330722\n",
      "Test f1                             0.343483\n",
      "Train precision                     0.247757\n",
      "Val precision                       0.247653\n",
      "Test precision                      0.259174\n",
      "Train recall                        0.497751\n",
      "Val recall                          0.497647\n",
      "Test recall                         0.509091\n",
      "Time                                  211.93\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 9, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (10, lstm_hidden_layer_n_neurons              6.0\n",
      "lstm_n_hidden_layers                     1.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          1.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons            25.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.502249\n",
      "Val accu                            0.502353\n",
      "Test accu                           0.490909\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.335835\n",
      "Val f1                              0.335951\n",
      "Test f1                             0.323282\n",
      "Train precision                     0.252254\n",
      "Val precision                       0.252358\n",
      "Test precision                      0.240992\n",
      "Train recall                        0.502249\n",
      "Val recall                          0.502353\n",
      "Test recall                         0.490909\n",
      "Time                                  211.97\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 10, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (11, lstm_hidden_layer_n_neurons              6.0\n",
      "lstm_n_hidden_layers                     1.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          1.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons            50.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.502249\n",
      "Val accu                            0.502353\n",
      "Test accu                           0.490909\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.335835\n",
      "Val f1                              0.335951\n",
      "Test f1                             0.323282\n",
      "Train precision                     0.252254\n",
      "Val precision                       0.252358\n",
      "Test precision                      0.240992\n",
      "Train recall                        0.502249\n",
      "Val recall                          0.502353\n",
      "Test recall                         0.490909\n",
      "Time                                  213.25\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 11, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (12, lstm_hidden_layer_n_neurons              6.0\n",
      "lstm_n_hidden_layers                     1.0\n",
      "bi_lstm                                  0.0\n",
      "n_hidden_layers                          1.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons           100.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.502249\n",
      "Val accu                            0.502353\n",
      "Test accu                           0.490909\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.335835\n",
      "Val f1                              0.335951\n",
      "Test f1                             0.323282\n",
      "Train precision                     0.252254\n",
      "Val precision                       0.252358\n",
      "Test precision                      0.240992\n",
      "Train recall                        0.502249\n",
      "Val recall                          0.502353\n",
      "Test recall                         0.490909\n",
      "Time                                  214.29\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 12, dtype: object)\n",
      "Error message: 'dict' object is not callable\n",
      "Error Importing this Row: (13, lstm_hidden_layer_n_neurons              6.0\n",
      "lstm_n_hidden_layers                     1.0\n",
      "bi_lstm                                  1.0\n",
      "n_hidden_layers                          1.0\n",
      "batch_size                             128.0\n",
      "learning_rate                           0.01\n",
      "dense_hidden_layer_n_neurons             6.0\n",
      "activation                              relu\n",
      "dropout_prob                             0.1\n",
      "batch_normalisation                      0.0\n",
      "dense_layer_type                       Dense\n",
      "attention_num_heads                      0.0\n",
      "Train accu                          0.502249\n",
      "Val accu                            0.502353\n",
      "Test accu                           0.490909\n",
      "Train balanced_accu                      NaN\n",
      "Val balanced_accu                        NaN\n",
      "Test balanced_accu                       NaN\n",
      "Train f1                            0.335835\n",
      "Val f1                              0.335951\n",
      "Test f1                             0.323282\n",
      "Train precision                     0.252254\n",
      "Val precision                       0.252358\n",
      "Test precision                      0.240992\n",
      "Train recall                        0.502249\n",
      "Val recall                          0.502353\n",
      "Test recall                         0.490909\n",
      "Time                                  254.63\n",
      "verbose                                 True\n",
      "random_state                      19260817.0\n",
      "loss_function                   CrossEntropy\n",
      "num_epochs                             250.0\n",
      "grad_clip                              False\n",
      "Train balanced_accuracy                  0.5\n",
      "Val balanced_accuracy                    0.5\n",
      "Test balanced_accuracy                   0.5\n",
      "Name: 13, dtype: object)\n",
      "Successfully read in tuning result of 14 rows\n",
      "Successfully set tuning output address\n",
      "Successfully set best model output address\n",
      "\n",
      "Default combo: [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0] \n",
      "\n",
      "\n",
      "ROUND 1\n",
      "\n",
      "Round 1 \n",
      "Hyperparameter: lstm_n_hidden_layers (index: 1) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/Users/tg.chenny/Desktop/3. Self Projects/2. PythonProject/Incomplete/DeepTrade/PrivatePackages/models/LSTM.py:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:233.)\n",
      "  self.x = torch.FloatTensor(x)\n",
      "/Users/tg.chenny/Desktop/3. Self Projects/2. PythonProject/Incomplete/DeepTrade/PrivatePackages/models/LSTM.py:221: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax_out = self.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/250], Loss: 0.6932\n",
      "Epoch [200/250], Loss: 0.6932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained and Tested combination 15 of 921600: (0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0), taking 241.37 seconds to get val score of 0.5024\n",
      "        Current best combo: (0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0) with val score 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tg.chenny/Desktop/3. Self Projects/2. PythonProject/Incomplete/DeepTrade/PrivatePackages/models/LSTM.py:221: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax_out = self.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/250], Loss: 0.6932\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_8547/701709009.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mjiaocheng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_best_model_saving_address\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../models/tmp_models/jiaocheng_{MODEL}_{LABEL}.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mjiaocheng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/3. Self Projects/2. PythonProject/Incomplete/DeepTrade/PrivatePackages/JiaoCheng.py\u001b[0m in \u001b[0;36mtune\u001b[0;34m(self, key_stats_only)\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_up_to\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_and_test_combo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_already_trained_best_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/3. Self Projects/2. PythonProject/Incomplete/DeepTrade/PrivatePackages/JiaoCheng.py\u001b[0m in \u001b[0;36m_train_and_test_combo\u001b[0;34m(self, combo)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;31m# get time and fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/3. Self Projects/2. PythonProject/Incomplete/DeepTrade/PrivatePackages/models/LSTM.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_x, train_y, initial_model)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_train_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# It may be accessed twice, so we use a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "jiaocheng = JiaoCheng.JiaoCheng()\n",
    "\n",
    "from models.LSTM import LSTMC_pt as LSTMC\n",
    "\n",
    "jiaocheng.read_in_model(LSTMC, 'Classification')\n",
    "\n",
    "jiaocheng.read_in_data(train_x, train_y, val_x, val_y, test_x, test_y)\n",
    "\n",
    "parameter_choices = {\n",
    "    'lstm_hidden_layer_n_neurons': [6, 12, 25, 50, 100],\n",
    "    'lstm_n_hidden_layers': [1, 2, 3],\n",
    "    'bi_lstm': [False, True],\n",
    "    'n_hidden_layers': [1, 2, 3],\n",
    "    'batch_size': [64, 128, 256, 512],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "    'dense_hidden_layer_n_neurons': [6, 12, 25, 50, 100],\n",
    "    'activation': ['relu', 'sigmoid', 'tanh', 'softmax'],\n",
    "    'dropout_prob': [0, 0.1, 0.3, 0.5],\n",
    "    'batch_normalisation': [False, True],\n",
    "    'dense_layer_type': ['Dense', 'Residual'],\n",
    "    'attention_num_heads': [0, 1],\n",
    "\n",
    "}\n",
    "\n",
    "jiaocheng.set_hyperparameters(parameter_choices)\n",
    "\n",
    "jiaocheng.set_non_tuneable_hyperparameters({'verbose' : True, 'random_state' : 19260817, 'loss_function':'CrossEntropy', 'num_epochs':250, 'grad_clip': False})\n",
    "\n",
    "jiaocheng.set_tuning_order(['lstm_n_hidden_layers', 'n_hidden_layers', 'lstm_hidden_layer_n_neurons', 'dense_hidden_layer_n_neurons', \n",
    "                            'bi_lstm', 'attention_num_heads', 'activation', 'dense_layer_type',\n",
    "                            'dropout_prob', 'batch_size', 'batch_normalisation', 'learning_rate'])\n",
    "\n",
    "jiaocheng.set_hyperparameter_default_values({\n",
    "    'lstm_hidden_layer_n_neurons': 6,\n",
    "    'lstm_n_hidden_layers': 1,\n",
    "    'bi_lstm': False,\n",
    "    'n_hidden_layers': 1,\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.01,\n",
    "    'dense_hidden_layer_n_neurons': 6,\n",
    "    'activation': 'relu',\n",
    "    'dropout_prob': 0.1,\n",
    "    'batch_normalisation': False,\n",
    "    'dense_layer_type': 'Dense',\n",
    "    'attention_num_heads': 0}\n",
    ")\n",
    "\n",
    "try:\n",
    "    jiaocheng.read_in_tuning_result_df(f'../models/tuning/jiaocheng_{MODEL}_{LABEL}.csv')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "jiaocheng.set_tuning_result_saving_address(f'../models/tuning/jiaocheng_{MODEL}_{LABEL}.csv')\n",
    "jiaocheng.set_best_model_saving_address(f'../models/tmp_models/jiaocheng_{MODEL}_{LABEL}.pickle')\n",
    "\n",
    "jiaocheng.tune()\n",
    "\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataLoader(Dataset):\n",
    "    def __init__(self, x, y = None):\n",
    "        self.x = torch.FloatTensor(x)\n",
    "        if y is not None:\n",
    "            if type(y) == np.ndarray:\n",
    "                self.y = torch.FloatTensor(y)\n",
    "            elif type(y) == pd.core.series.Series or type(y) == pd.core.frame.DataFrame:\n",
    "                self.y = y\n",
    "        self.len = len(x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            if type(self.y) == pd.core.series.Series:\n",
    "                y = torch.tensor(self.y.iloc[idx], dtype=torch.float32)\n",
    "                return self.x[idx], y\n",
    "            elif type(self.y) == pd.core.frame.DataFrame:\n",
    "                y = torch.tensor(self.y.iloc[idx].values, dtype=torch.float32)\n",
    "                return self.x[idx], y\n",
    "            else:\n",
    "                self.x[idx], self.y[idx]\n",
    "        except:\n",
    "            return self.x[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataLoader(Dataset):\n",
    "    def __init__(self, x, y = None):\n",
    "        self.x = torch.FloatTensor(x)\n",
    "        if y is not None:\n",
    "            if type(y) == np.ndarray or type(y) == list:\n",
    "                self.y = torch.FloatTensor(y)\n",
    "            elif type(y) == pd.core.series.Series or type(y) == pd.core.frame.DataFrame:\n",
    "                self.y = y\n",
    "        self.len = len(x)\n",
    "\n",
    "        print(self.x)\n",
    "        print(self.y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            if type(self.y) == pd.core.series.Series:\n",
    "                y = torch.tensor(self.y.iloc[idx], dtype=torch.float32)\n",
    "                return self.x[idx], y\n",
    "            elif type(self.y) == pd.core.frame.DataFrame:\n",
    "                y = torch.tensor(self.y.iloc[idx].values, dtype=torch.float32)\n",
    "                return self.x[idx], y\n",
    "            else:\n",
    "                self.x[idx], self.y[idx]\n",
    "        except:\n",
    "            return self.x[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataLoader(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_9941/2468511383.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "for batch_idx, (x, y) in enumerate(train_loader):\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
