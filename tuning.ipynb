{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingStrategy:\n",
    "\n",
    "    def __init__(self, short_term, long_term, price_range, amp_window, increase_holding, decrease_holding, amp_lo_threshold, amp_hi_threshold, mse_threshold):\n",
    "        self.SHORT_TERM = short_term\n",
    "        self.LONG_TERM = long_term\n",
    "        self.PRICE_RANGE = price_range\n",
    "        self.AMP_WINDOW = amp_window\n",
    "        self.INCREASE_HOLDING = increase_holding\n",
    "        self.DECREASE_HOLDING = decrease_holding\n",
    "        self.AMP_LO_THRESHOLD = amp_lo_threshold\n",
    "        self.AMP_HI_THRESHOLD = amp_hi_threshold\n",
    "        self.MSE_THRESHOLD = mse_threshold\n",
    "\n",
    "\n",
    "    def getMyPosition(self, prcSoFar):\n",
    "    \n",
    "        day = prcSoFar.shape[1]\n",
    "        train_data = self.data_process(prcSoFar)\n",
    "\n",
    "        currentPrices = prcSoFar[:,day-1] # price of last day\n",
    "\n",
    "        amp = self.range_so_far(train_data, day)\n",
    "        \n",
    "        # Get long term and short term average prices\n",
    "        for stock in range(50):\n",
    "            single_stock_data = train_data[train_data['stock'] == stock]\n",
    "            single_stock_data.index = range(len(single_stock_data))\n",
    "\n",
    "            # Use short term and long term average to determine sign\n",
    "            long_mean = single_stock_data.loc[day - self.LONG_TERM: (day-1), 'closePrice'].mean()\n",
    "            short_mean = single_stock_data.loc[day - self.SHORT_TERM: (day-1), 'closePrice'].mean()\n",
    "            today_sign = np.sign(short_mean - long_mean)\n",
    "\n",
    "            # Use a price window to make decision\n",
    "            n_day_diff = single_stock_data.loc[day-self.PRICE_RANGE, 'closePrice'] - single_stock_data.loc[day-1, 'closePrice']\n",
    "\n",
    "            # Calculate the MSE of price movement during the range\n",
    "            n_day_gap = np.diff(single_stock_data.loc[day-self.PRICE_RANGE:day-1, 'closePrice'])\n",
    "            LR = LinearRegression(n_jobs=-1).fit(np.array(range(self.PRICE_RANGE-1)).reshape(-1,1), n_day_gap.reshape(-1,1))\n",
    "            n_day_mse = mean_squared_error(n_day_gap, LR.predict(np.array(range(self.PRICE_RANGE-1)).reshape(-1,1)))\n",
    "            \n",
    "            if np.abs(n_day_diff) <= amp[stock]/self.AMP_LO_THRESHOLD or n_day_mse > self.MSE_THRESHOLD:\n",
    "                pass\n",
    "                \n",
    "            elif np.abs(n_day_diff) >= amp[stock]/self.AMP_HI_THRESHOLD:\n",
    "                value = today_sign * self.DECREASE_HOLDING\n",
    "                self.currentPos[stock] -= value//currentPrices[stock]\n",
    "        \n",
    "            else:\n",
    "                value = today_sign * self.INCREASE_HOLDING\n",
    "                self.currentPos[stock] += value//currentPrices[stock]\n",
    "                \n",
    "            return self.currentPos\n",
    "\n",
    "\n",
    "    def data_process(self, prcAll):\n",
    "        \"\"\"\n",
    "        Convert raw price data into closeprice columns \n",
    "        \"\"\"\n",
    "        closePrice = []\n",
    "        for stock in range(50):\n",
    "            closePrice.extend(prcAll[stock])\n",
    "\n",
    "        dates = []\n",
    "        for stock in range(50):\n",
    "            for day in range(prcAll.shape[1]):\n",
    "                dates.append(day)\n",
    "\n",
    "        stocks = []\n",
    "\n",
    "        for stock in range(50):\n",
    "            stocks.extend([stock]*prcAll.shape[1])\n",
    "        full_data = pd.DataFrame({'date': dates, 'stock': stocks, 'closePrice': closePrice})\n",
    "        full_data['log_closePrice'] = np.log(full_data['closePrice'])\n",
    "        return full_data\n",
    "\n",
    "\n",
    "    def range_so_far(self, data, day):\n",
    "        amp = []\n",
    "        for j in range(50):\n",
    "            single_stock_data = data[data['stock'] == j]\n",
    "            single_stock_data.index = range(len(single_stock_data))\n",
    "\n",
    "            base_range = max(single_stock_data.loc[day-self.AMP_WINDOW:day-1, 'closePrice']) -  min(single_stock_data.loc[day-self.AMP_WINDOW:day-1, 'closePrice'])\n",
    "            amp.append(base_range)\n",
    "        return amp\n",
    "    \n",
    "    def predict(self, prcHist, period_start_date):\n",
    "\n",
    "        nInst = 50\n",
    "\n",
    "        commRate = 0.0010\n",
    "        dlrPosLimit = 10000\n",
    "\n",
    "        self.currentPos = np.zeros(nInst)\n",
    "\n",
    "        cash = 0\n",
    "        curPos = np.zeros(nInst)\n",
    "        totDVolume = 0\n",
    "        value = 0\n",
    "        todayPLL = []\n",
    "        (_,nt) = prcHist.shape\n",
    "        for t in range(period_start_date, period_start_date+250): \n",
    "            prcHistSoFar = prcHist[:,:t]\n",
    "            newPosOrig = self.getMyPosition(prcHistSoFar)\n",
    "            curPrices = prcHistSoFar[:,-1] #prcHist[:,t-1]\n",
    "            posLimits = np.array([int(x) for x in dlrPosLimit / curPrices])\n",
    "            clipPos = np.clip(newPosOrig, -posLimits, posLimits)\n",
    "            newPos = np.array([np.trunc(x) for x in clipPos])\n",
    "            deltaPos = newPos - curPos\n",
    "            dvolumes = curPrices * np.abs(deltaPos)\n",
    "            dvolume = np.sum(dvolumes)\n",
    "            totDVolume += dvolume\n",
    "            comm = dvolume * commRate\n",
    "            cash -= curPrices.dot(deltaPos) + comm\n",
    "            curPos = np.array(newPos)\n",
    "            posValue = curPos.dot(curPrices)\n",
    "            todayPL = cash + posValue - value\n",
    "            todayPLL.append(todayPL)\n",
    "            value = cash + posValue\n",
    "            ret = 0.0\n",
    "            if (totDVolume > 0):\n",
    "                ret = value / totDVolume\n",
    "        pll = np.array(todayPLL)\n",
    "        (plmu,plstd) = (np.mean(pll), np.std(pll))\n",
    "        annSharpe = 0.0\n",
    "        if (plstd > 0):\n",
    "            annSharpe = np.sqrt(250) * plmu / plstd\n",
    "        \n",
    "        return plmu - 0.1*plstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPrices(fn):\n",
    "    global nt, nInst\n",
    "    df=pd.read_csv(fn, sep='\\s+', header=None, index_col=None)\n",
    "    nt, nInst = df.values.shape\n",
    "    return (df.values).T\n",
    "\n",
    "data = loadPrices('./data/prices.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05/07/2023\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as s\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import t\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class YangZhouB:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialise class \"\"\"\n",
    "        self._initialise_objects()\n",
    "\n",
    "        print('YangZhouB Initialised')\n",
    "\n",
    "\n",
    "\n",
    "    def _initialise_objects(self):\n",
    "        \"\"\" Helper to initialise objects \"\"\"\n",
    "        self.train_x = None\n",
    "        self.train_y = None\n",
    "        self.val_x = None\n",
    "        self.val_y = None\n",
    "        self.test_x = None\n",
    "        self.test_y = None\n",
    "        self.tuning_result = None\n",
    "        self.model = None\n",
    "        self.parameter_choices = None\n",
    "        self.hyperparameters = None\n",
    "        self.feature_n_ningxiang_score_dict = None\n",
    "        self.non_tuneable_parameter_choices = list()\n",
    "        self.checked = None\n",
    "        self.result = None\n",
    "        self.checked_core = None\n",
    "        self.been_best = None\n",
    "        self.been_cruised = None\n",
    "        self.tuning_result_saving_address = None\n",
    "        self.object_saving_address = None\n",
    "        self._parameter_value_map_index = None\n",
    "        self._seed = 19260817\n",
    "        self.best_score = -np.inf\n",
    "        self.best_combo = None\n",
    "        self.best_clf = None\n",
    "        self.clf_type = None\n",
    "        self.n_items = None\n",
    "        self._core = None\n",
    "        self._cruise_indices = None\n",
    "        self._cruise_indices_values = None\n",
    "        self._cruise_combinations = None\n",
    "        self._restarts = 0\n",
    "        self._cruising = True\n",
    "        self._surrounding_vectors = None\n",
    "        self._total_combos = None\n",
    "        self._tune_features = False\n",
    "        self._up_to = 0\n",
    "        self._n_cruise_coord = None\n",
    "        self._cruising_up_to = 0\n",
    "        self._feature_combo_n_index_map = None\n",
    "        self.best_model_saving_address = None\n",
    "\n",
    "        self.regression_extra_output_columns = ['Train r2', 'Val r2', 'Test r2', \n",
    "            'Train RMSE', 'Val RMSE', 'Test RMSE', 'Train MAPE', 'Val MAPE', 'Test MAPE', 'Time']\n",
    "        self.classification_extra_output_columns = ['Train accu', 'Val accu', 'Test accu', \n",
    "            'Train balanced_accu', 'Val balanced_accu', 'Test balanced_accu', 'Train f1', 'Val f1', 'Test f1', \n",
    "            'Train precision', 'Val precision', 'Test precision', 'Train recall', 'Val recall', 'Test recall', 'Time']\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_data(self, data):\n",
    "        \"\"\" Reads in train validate test data for tuning \"\"\"\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_model(self, model, type):\n",
    "        \"\"\" Reads in underlying model object for tuning, and also read in what type of model it is \"\"\"\n",
    "\n",
    "        assert type == 'Classification' or type == 'Regression' # check\n",
    "\n",
    "        # record\n",
    "        self.model = model\n",
    "        self.clf_type = type \n",
    "\n",
    "        print(f'Successfully read in model {self.model}, which is a {self.clf_type} model')\n",
    "\n",
    "\n",
    "\n",
    "    def set_hyperparameters(self, parameter_choices):\n",
    "        \"\"\" Input hyperparameter choices \"\"\"\n",
    "\n",
    "        self.parameter_choices = parameter_choices\n",
    "        self._sort_hyperparameter_choices()\n",
    "\n",
    "        self.hyperparameters = list(parameter_choices.keys())\n",
    "\n",
    "        # automatically calculate how many different values in each hyperparameter\n",
    "        self.n_items = [len(parameter_choices[key]) for key in self.hyperparameters]\n",
    "        self.num_hyperparameters = {hyperparameter:len(parameter_choices[hyperparameter]) for hyperparameter in self.hyperparameters}\n",
    "        self._total_combos = np.prod(self.n_items)\n",
    "\n",
    "        # automatically setup checked and result arrays and tuning result dataframe\n",
    "        self._get_checked_and_result_array()\n",
    "        self._setup_tuning_result_df()\n",
    "\n",
    "        print(\"Successfully recorded hyperparameter choices\")\n",
    "\n",
    "\n",
    "    \n",
    "    def _sort_hyperparameter_choices(self):\n",
    "        \"\"\" Helper to ensure all hyperparameter choice values are in order from lowest to highest \"\"\"\n",
    "\n",
    "        for key in self.parameter_choices:\n",
    "            tmp = copy.deepcopy(list(self.parameter_choices[key]))\n",
    "            tmp.sort()\n",
    "            self.parameter_choices[key] = tuple(tmp)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_checked_and_result_array(self):\n",
    "        \"\"\" Helper to set up checked and result array \"\"\"\n",
    "\n",
    "        self.checked = np.zeros(shape=self.n_items)\n",
    "        self.result = np.zeros(shape=self.n_items)\n",
    "        self.checked_core = np.zeros(shape=self.n_items)\n",
    "        self.been_best = np.zeros(shape=self.n_items) # strictly for last part of Guidance Algorithm\n",
    "        self.been_cruised = np.zeros(shape=self.n_items)\n",
    "\n",
    "\n",
    "\n",
    "    def _setup_tuning_result_df(self):\n",
    "        \"\"\" Helper to set up tuning result dataframe \"\"\"\n",
    "\n",
    "        tune_result_columns = copy.deepcopy(self.hyperparameters)\n",
    "\n",
    "        if self._tune_features:\n",
    "            tune_result_columns.append('feature combo ningxiang score')\n",
    "\n",
    "        # Different set of metric columns for different types of models\n",
    "        if self.clf_type == 'Classification':\n",
    "            tune_result_columns.extend(self.classification_extra_output_columns)\n",
    "        elif self.clf_type == 'Regression':\n",
    "            tune_result_columns.extend(self.regression_extra_output_columns)\n",
    "\n",
    "        self.tuning_result = pd.DataFrame({col:list() for col in tune_result_columns})\n",
    "\n",
    "\n",
    "\n",
    "    def set_non_tuneable_hyperparameters(self, non_tuneable_hyperparameter_choice):\n",
    "        \"\"\" Input Non tuneable hyperparameter choice \"\"\"\n",
    "\n",
    "        if type(non_tuneable_hyperparameter_choice) is not dict:\n",
    "            raise TypeError('non_tuneable_hyeprparameters_choice must be dict, please try again')\n",
    "            \n",
    "        \n",
    "        for nthp in non_tuneable_hyperparameter_choice:\n",
    "            if type(non_tuneable_hyperparameter_choice[nthp]) in (set, list, tuple, dict):\n",
    "                raise TypeError('non_tuneable_hyperparameters_choice must not be of array-like type')\n",
    "                \n",
    "\n",
    "        self.non_tuneable_parameter_choices = non_tuneable_hyperparameter_choice\n",
    "\n",
    "        print(\"Successfully recorded non_tuneable_hyperparameter choices\")\n",
    "\n",
    "\n",
    "\n",
    "    def set_features(self, ningxiang_output):\n",
    "        \"\"\" Input features \"\"\"\n",
    "    \n",
    "        if type(ningxiang_output) is not dict:\n",
    "            raise TypeError(\"Please ensure NingXiang output is a dict\")\n",
    "            \n",
    "        \n",
    "        if not self.hyperparameters:\n",
    "            raise AttributeError(\"Missing hyperparameter choices, please run .set_hyperparameters() first\")\n",
    "            \n",
    "        \n",
    "        for feature in list(ningxiang_output.keys())[-1]:\n",
    "            if feature not in list(self.train_x.columns):\n",
    "                raise ValueError(f'feature {feature} in ningxiang output is not in train_x. Please try again')\n",
    "                \n",
    "            if feature not in list(self.val_x.columns):\n",
    "                raise ValueError(f'feature {feature} in ningxiang output is not in val_x. Please try again')\n",
    "                \n",
    "            if feature not in list(self.test_x.columns):\n",
    "                raise ValueError(f'feature {feature} in ningxiang output is not in test_x. Please try again')\n",
    "                \n",
    "        \n",
    "        # sort ningxiang just for safety, and store up\n",
    "        ningxiang_output_sorted = self._sort_features(ningxiang_output)\n",
    "        self.feature_n_ningxiang_score_dict = ningxiang_output_sorted\n",
    "\n",
    "        # activate this switch\n",
    "        self._tune_features = True\n",
    "\n",
    "        # update previous internal structures based on first set of hyperparameter choices\n",
    "        ##here used numbers instead of tuples as the values in parameter_choices; thus need another mapping to get map back to the features\n",
    "        self.parameter_choices['features'] = tuple([i for i in range(len(ningxiang_output_sorted))])\n",
    "        self._feature_combo_n_index_map = {i: list(ningxiang_output_sorted.keys())[i] for i in range(len(ningxiang_output_sorted))}\n",
    "\n",
    "        self.hyperparameters = list(self.parameter_choices.keys())\n",
    "\n",
    "        # automatically calculate how many different values in each hyperparameter\n",
    "        self.n_items = [len(self.parameter_choices[key]) for key in self.hyperparameters]\n",
    "        self.num_hyperparameters = {hyperparameter:len(self.parameter_choices[hyperparameter]) for hyperparameter in self.hyperparameters}\n",
    "        self._total_combos = np.prod(self.n_items)\n",
    "\n",
    "        # automatically calculate all combinations and setup checked and result arrays and tuning result dataframe\n",
    "        self._get_checked_and_result_array()\n",
    "        self._setup_tuning_result_df()\n",
    "\n",
    "        print(\"Successfully recorded tuneable feature combination choices and updated relevant internal structures\")\n",
    "\n",
    "\n",
    "    \n",
    "    def _sort_features(self, ningxiang_output):\n",
    "        \"\"\" Helper for sorting features based on NingXiang values (input dict output dict) \"\"\"\n",
    "\n",
    "        ningxiang_output_list = [(key, ningxiang_output[key]) for key in ningxiang_output]\n",
    "\n",
    "        ningxiang_output_list.sort(key = lambda x:x[1])\n",
    "\n",
    "        ningxiang_output_sorted = {x[0]:x[1] for x in ningxiang_output_list}\n",
    "\n",
    "        return ningxiang_output_sorted\n",
    "\n",
    "\n",
    "\n",
    "    def _get_core(self):\n",
    "        \"\"\" Helper to calculate core \"\"\"\n",
    "        self._core = [int(i/2) for i in self.n_items]\n",
    "\n",
    "\n",
    "\n",
    "    def _get_cruise_combinations(self):\n",
    "        \"\"\" Helper to cruise combinations \"\"\"\n",
    "\n",
    "        self._get_cruise_indices_values()\n",
    "        self._generate_cruise_combinations() # first get cruise indicies, then use indicies to get combinations\n",
    "\n",
    "        self._n_cruise_coord = len(self._cruise_combinations)\n",
    "\n",
    "\n",
    "\n",
    "    def _get_cruise_indices_values(self):\n",
    "        \"\"\" Helper to get cruise indices values of each dimension which serves as building blocks for cruise combinations \"\"\"\n",
    "\n",
    "        self._cruise_indices = dict()\n",
    "        for hyperparameter in self.hyperparameters:\n",
    "            self._cruise_indices[hyperparameter] = self._get_cruise_indices_1d(d_val = self.num_hyperparameters[hyperparameter], max_jump = 5)\n",
    "\n",
    "        self._cruise_indices_values = list(self._cruise_indices.values())\n",
    "\n",
    "\n",
    "\n",
    "    def _get_cruise_indices_1d(self, d_val, max_jump = 5): \n",
    "        \"\"\" Helper that returns the appropriate cruise indices based on the number of values in dimension. Second argument controls maximum split size, defaulted to 5 \"\"\"\n",
    "\n",
    "        assert type(d_val) is int and type(max_jump) is int, \"Error: type of input(s) is not int\"\n",
    "        assert max_jump >= 1, \"Error: max_jump must be >= 1\"\n",
    "\n",
    "        gap = d_val - 1\n",
    "        split = ((gap-1)//max_jump)\n",
    "\n",
    "        jump = self._find_gaps(split, gap)\n",
    "\n",
    "        cruise_indices_1d = self._find_cruise_indices_1d(jump)\n",
    "\n",
    "        return cruise_indices_1d\n",
    "\n",
    "\n",
    "\n",
    "    def _find_gaps(self, split, gap):\n",
    "        \"\"\" Helper that finds the size of jumps between each element of the final cruise indices, as evenly split as possible with jump size <= 5 \"\"\"\n",
    "\n",
    "        if split > 0:\n",
    "            jump = [gap//(split+1) for i in range(split+1)]\n",
    "            diff = gap - sum(jump)\n",
    "            if diff:\n",
    "                for i in range(diff):\n",
    "                    jump[i] += 1\n",
    "        else:\n",
    "            jump = [gap]\n",
    "\n",
    "        return jump\n",
    "\n",
    "\n",
    "\n",
    "    def _find_cruise_indices_1d(self, jump):\n",
    "        \"\"\" Helper that finds the actual cruise_indices based on gaps \"\"\"\n",
    "\n",
    "        cruise_indices_1d = [0]\n",
    "        for i in range(len(jump)):\n",
    "            cruise_indices_1d.append(sum(jump[:i+1]))\n",
    "\n",
    "        if cruise_indices_1d == [0, 0]:\n",
    "            cruise_indices_1d = [0]\n",
    "            \n",
    "        return cruise_indices_1d\n",
    "\n",
    "\n",
    "\n",
    "    def _generate_cruise_combinations(self):\n",
    "        \"\"\" Helper that generates the actual cruise combinations based on cruise indicies \"\"\"\n",
    "        ##ALGORITHM: how to generate all combinations of any dimensions given each dimension has different values\n",
    "        self._cruise_combinations = [[]]\n",
    "        for i in range(len(self._cruise_indices_values)):\n",
    "\n",
    "            tmp = copy.deepcopy(self._cruise_combinations)\n",
    "            self._cruise_combinations = list()\n",
    "\n",
    "            for x in tmp:\n",
    "\n",
    "                for k in self._cruise_indices_values[i]:\n",
    "                    y = copy.deepcopy(x)\n",
    "                    \n",
    "                    y.append(k)\n",
    "\n",
    "                    self._cruise_combinations.append(y)\n",
    "\n",
    "\n",
    "\n",
    "    def _sort_cruise_combos(self, max_combo):\n",
    "        \"\"\" sort the cruise combos based on Euclidean distance from current max\"\"\"\n",
    "\n",
    "        edist = list(cdist([max_combo], self._cruise_combinations).flatten())\n",
    "        ordered_cruise_combos = [(self._cruise_combinations[i], edist[i]) for i in range(len(self._cruise_combinations))]\n",
    "\n",
    "        ordered_cruise_combos.sort(reverse=True, key=lambda x: x[1])\n",
    "\n",
    "        sorted_cruise_combos = [ordered_cruise_combos[i][0] for i in range(len(ordered_cruise_combos))]\n",
    "\n",
    "        return sorted_cruise_combos\n",
    "\n",
    "    \n",
    "\n",
    "    def _get_max_surrounding_mean_sd(self):\n",
    "        \"\"\" Helper to get the surrounding mean and sd given the current maximum \"\"\"\n",
    "\n",
    "        best_combo_surrounding_combos = self._get_surrounding_step_combos(self.best_combo)\n",
    "        best_combo_surrounding_scores = [self.best_score]\n",
    "        for combo in best_combo_surrounding_combos:\n",
    "            best_combo_surrounding_scores.append(self.result[tuple(combo)])\n",
    "\n",
    "        max_surrounding_mean = s.mean(best_combo_surrounding_scores)\n",
    "        max_surrounding_sd = s.stdev(best_combo_surrounding_scores)\n",
    "\n",
    "        return max_surrounding_mean, max_surrounding_sd\n",
    "\n",
    "\n",
    "\n",
    "    def _cruise_warning_threshold(self, max_surrounding_mean, max_surrounding_sd, max_surrounding_n):\n",
    "        \"\"\" Helper that gets the warning threshold by (mean of best_combo surrounds - halfwidth) \"\"\"\n",
    "\n",
    "        # use 0.95 (one sided test)\n",
    "        qt = t.ppf(0.95, max_surrounding_n-1) \n",
    "        halfwidth = max_surrounding_sd * qt * 1/np.sqrt(max_surrounding_n)\n",
    "\n",
    "        return max_surrounding_mean - halfwidth\n",
    "\n",
    "\n",
    "\n",
    "    def _CruiseSystem(self):\n",
    "        \"\"\" Helper that performs cruising \"\"\"\n",
    "\n",
    "        # get cruise combos in sorted order (furthest away from current max)\n",
    "        sorted_cruise_combos = self._sort_cruise_combos(self.best_combo)\n",
    "\n",
    "        # calculate warning threshold by getting max_surrounding_sd first\n",
    "        max_surrounding_mean, max_surrounding_sd = self._get_max_surrounding_mean_sd()\n",
    "\n",
    "        warning_threshold = self._cruise_warning_threshold(max_surrounding_mean, max_surrounding_sd, len(self._surrounding_vectors))\n",
    "\n",
    "        # check each cruise combo\n",
    "        for cruise_combo in sorted_cruise_combos:\n",
    "\n",
    "            # only search if it hasn't been cruised before (if has then is not an artifect of significance)\n",
    "            if not self.been_cruised[tuple(cruise_combo)]:\n",
    "                \n",
    "                self._cruising_up_to += 1\n",
    "                print(f'Cruising Coordrdinate {self._cruising_up_to} of {self._n_cruise_coord}\\n')\n",
    "                \n",
    "                self.been_cruised[tuple(cruise_combo)] = 2 # actually been cruised\n",
    "\n",
    "                # if above warning threshold, then stop cruise and restart guide\n",
    "                if self.result[tuple(cruise_combo)] >= warning_threshold:\n",
    "                   \n",
    "                    print(f\"Cruise suspended due to suspicious case\")\n",
    "                    \n",
    "                    return cruise_combo\n",
    "\n",
    "\n",
    "        # if reach here then all cruise indicies checked. can safely say end cruise\n",
    "        self._cruising = False\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def _get_core(self):\n",
    "        \"\"\" Helper to calculate core \"\"\"\n",
    "\n",
    "        self._core = [int(i/2) for i in self.n_items]\n",
    "\n",
    "\n",
    "\n",
    "    def _new_combos(self, core, vector):\n",
    "        \"\"\" Helper that gets particular COORDINATE using a move in direction of VECTOR from particular CORE \"\"\"\n",
    "\n",
    "        assert len(core) == len(vector)\n",
    "\n",
    "        new_combo = list()\n",
    "        for i in range(len(vector)):\n",
    "            val = core[i] + vector[i]\n",
    "            if val >= self.n_items[i] or val < 0: # check whether combo is still in the field\n",
    "                return False\n",
    "            new_combo.append(val)\n",
    "\n",
    "        return new_combo\n",
    "\n",
    "\n",
    "\n",
    "    def _xlnx(self, x):\n",
    "        \"\"\" Helper that returns x*ln(x), rounding up to next int \"\"\"\n",
    "        y = int(x*np.log(x))+1\n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "    def _find_new_core(self, surrounding_combos, core):\n",
    "        \"\"\" Helper that finds new cores - only those candidates with difference between core and treatment < 0.005 \"\"\"\n",
    "\n",
    "        new_cores = []\n",
    "        tmp_new_cores = list()\n",
    "        \n",
    "        for i in range(len(surrounding_combos)): \n",
    "\n",
    "            diff = self.result[tuple(core)] - self.result[tuple(surrounding_combos[i])]\n",
    "\n",
    "            if diff <= 0.005:\n",
    "                if self.checked_core[ tuple(surrounding_combos[i]) ] == 0:\n",
    "                    tmp_new_cores.append([tuple(surrounding_combos[i]), diff])\n",
    "                        \n",
    "        # # sort the tmp new cores list according to p values\n",
    "        # tmp_new_cores.sort(key = lambda x:x[1])\n",
    "\n",
    "        # # calculate how many new cores to accept according to the dimension of the grid (x = dim; accept x*ln(x))\n",
    "        # n_accept = self._xlnx(len(core))\n",
    "        \n",
    "        for i in range(len(tmp_new_cores)):\n",
    "            # if i >= n_accept:\n",
    "            #     break\n",
    "\n",
    "            new_cores.append(tmp_new_cores[i][0])\n",
    "            self.checked_core[ tmp_new_cores[i][0] ] = 1\n",
    "\n",
    "        return new_cores\n",
    "\n",
    "\n",
    "\n",
    "    def _get_surrounding_step_vectors(self, core):\n",
    "        \"\"\" find all horizontal steps \"\"\"\n",
    "\n",
    "        all_steps = list()\n",
    "\n",
    "        for i in range(len(core)):\n",
    "            for val in [-1, 1]:\n",
    "                tmp = [0 for i in range(len(core))]\n",
    "                tmp[i] = val\n",
    "        \n",
    "                all_steps.append(tmp)\n",
    "        \n",
    "        return all_steps\n",
    "    \n",
    "\n",
    "\n",
    "    def _get_surrounding_step_combos(self, core):\n",
    "        \"\"\" find all vectors that are one horizontal steps away from core \"\"\"\n",
    "\n",
    "        surrounding_combos = list()\n",
    "        for step in self._surrounding_vectors:\n",
    "\n",
    "            add = 1\n",
    "            candidate_surrounding_combo = list()\n",
    "\n",
    "            for i in range(len(core)):\n",
    "                new_index = core[i]+step[i]\n",
    "                if new_index < 0 or new_index >= self.n_items[i]:\n",
    "                    add = 0\n",
    "                    break\n",
    "                else:\n",
    "                    candidate_surrounding_combo.append(new_index)\n",
    "\n",
    "            if add:    \n",
    "                surrounding_combos.append(candidate_surrounding_combo)\n",
    "\n",
    "        return surrounding_combos\n",
    "\n",
    "\n",
    "\n",
    "    def _get_new_cores(self, core):\n",
    "        \"\"\" Helper that gets new cores given old cores \"\"\"\n",
    "\n",
    "        # if (should be rare) case where core has been a core before, then skip. For prevention of infinite loops\n",
    "        # 2 means actual checked core, 1 means appended to checked core list but not checked\n",
    "        if self.checked_core[tuple(core)] == 2:\n",
    "            return\n",
    "        else:\n",
    "            self.checked_core[tuple(core)] = 2 # actually been checked as a core\n",
    "\n",
    "        surrounding_combos = self._get_surrounding_step_combos(core)\n",
    "\n",
    "        # actually tune the surrounding combos\n",
    "        for combo in surrounding_combos:\n",
    "            \n",
    "            if self.checked[tuple(combo)] == 0:\n",
    "                self._up_to += 1\n",
    "                self._train_and_test_combo(combo)\n",
    "            else:\n",
    "                self._check_already_trained_best_score(combo)\n",
    "\n",
    "        # perform welch test and return surrounding combos that should be used as new core\n",
    "        new_cores = self._find_new_core(surrounding_combos, core)\n",
    "\n",
    "        return new_cores  \n",
    "\n",
    "\n",
    "\n",
    "    def _GuidanceSystem(self, core):\n",
    "        \"\"\" Helper that performs guidance search \"\"\"\n",
    "\n",
    "        if self._restarts == 0:\n",
    "            print(\"Guidance: initial round \\n\")\n",
    "        else:\n",
    "            print(\"Guidance: round\", self._restarts, '\\n')\n",
    "\n",
    "        print('\\tround', self._restarts, 'iteration: ', 0, '\\n')\n",
    "\n",
    "        # first get a surrounding 3^d tuned\n",
    "        new_cores = self._get_new_cores(core)\n",
    "        self.been_cruised[tuple(core)] = 1 # represent don't need to be added as a to cruised - but not cruised, rather a core\n",
    "\n",
    "        round = 1\n",
    "        while new_cores: # while new cores are being added\n",
    "            print('\\tround', self._restarts, \"iteration: \", round, \"\\n\") \n",
    "            round += 1\n",
    "\n",
    "            old_new_cores = copy.deepcopy(new_cores)\n",
    "            new_cores = list()\n",
    "\n",
    "            # for each of the new cores, 'recursively' tune and grab new cores; but each Iteration doesn't end until all cores of current round has been checked\n",
    "            for new_core in old_new_cores:\n",
    "                \n",
    "                new_new_cores = self._get_new_cores(new_core)\n",
    "\n",
    "                if not new_new_cores:\n",
    "                    new_new_cores = []\n",
    "\n",
    "                self.been_cruised[tuple(core)] == 1\n",
    "                \n",
    "                for new_new_core in new_new_cores:\n",
    "                    if self.checked_core[tuple(new_new_core)] == 0:\n",
    "                        new_cores.append(new_new_core)\n",
    "                        self.checked_core[tuple(new_new_core)] = 1 # represent added to checked core - to prevent repeated added to core\n",
    "\n",
    "\n",
    "        # for current max, get 3^d block. if new max happens to be found, continue to do 3^d block until no new max is found\n",
    "        # just a cheap way to flesh out the max (the goal of YangZhouB)\n",
    "        while self.been_best[tuple(self.best_combo)] == 0:\n",
    "\n",
    "            self.been_best[tuple(self.best_combo)] = 1 \n",
    "    \n",
    "            surrounding_combos = self._get_surrounding_step_combos(self.best_combo)\n",
    "            for combo in surrounding_combos:\n",
    "                \n",
    "                if self.checked[tuple(combo)] == 0:\n",
    "                    self._up_to += 1\n",
    "                    self._train_and_test_combo(combo)\n",
    "                else:\n",
    "                    self._check_already_trained_best_score(combo)\n",
    "\n",
    "        # print information of this round \n",
    "\n",
    "        print('% Combos Checked Thus Far:', int(sum(self.checked.reshape((np.prod(self.n_items))))), 'out of', np.prod(self.n_items), 'which is', f'{np.mean(self.checked).round(8)*100}%')\n",
    "\n",
    "\n",
    "\n",
    "    def tune(self, key_stats_only = False):\n",
    "        \"\"\" Begin tuning \"\"\"\n",
    "\n",
    "    \n",
    "        if self.model is None:\n",
    "            raise AttributeError(\" Missing model, please run .read_in_model() \")\n",
    "            \n",
    "\n",
    "        if self.tuning_result_saving_address is None:\n",
    "            raise AttributeError(\"Missing tuning result csv saving address, please run .set_tuning_result_saving_address() first\")\n",
    "\n",
    "        self.key_stats_only = key_stats_only\n",
    "\n",
    "        print(\"BEGIN TUNING\\n\\n\") \n",
    "        \n",
    "        # FIRST: get all cruise combinations as well as core, and tune all these\n",
    "        self._get_core()\n",
    "        self._get_cruise_combinations() \n",
    "\n",
    "        first_round_combinations = copy.deepcopy(self._cruise_combinations)\n",
    "        first_round_combinations.append(self._core) \n",
    "\n",
    "        random.seed(self._seed)\n",
    "        random.shuffle(first_round_combinations)\n",
    "\n",
    "        print(\"STAGE ZERO: Tune all Cruise combinations\\n\\n\")\n",
    "        for combo in first_round_combinations:\n",
    "            \n",
    "            if not self.checked[tuple(combo)]:\n",
    "\n",
    "                self._up_to += 1\n",
    "                self._train_and_test_combo(combo)\n",
    "            \n",
    "            else:\n",
    "                self._check_already_trained_best_score(combo)\n",
    "        \n",
    "\n",
    "        # SECOND: from the core combo, begin guidance system\n",
    "        self._surrounding_vectors = self._get_surrounding_step_vectors(self._core)\n",
    "\n",
    "        print('\\n')\n",
    "        print(\"STAGE ONE: Begin initial Guidance system\\n\\n\")\n",
    "\n",
    "        self._restarts = 0\n",
    "        self._GuidanceSystem(self._core) # Initial Round of Guidance\n",
    "        self._restarts += 1\n",
    "\n",
    "        # THIRD: Recursively Cruise and restart Guide if find a combo that is within halfwidth of mean of best combo surrounds\n",
    "        print(\"STAGE TWO: Begin Cruise system\\n\\n\")\n",
    "        self._cruising_up_to = 0\n",
    "        self._cruising = True\n",
    "        while self._cruising:\n",
    "            suspicious_case_combo = self._CruiseSystem()\n",
    "\n",
    "            if self._cruising:\n",
    "                self._GuidanceSystem(tuple(suspicious_case_combo))\n",
    "                self._restarts += 1\n",
    "\n",
    "        # FINALLY: Final extensive guidance search around maxes.\n",
    "        print(\"FINAL STAGE: Begin final Guidance system\\n\\n\")\n",
    "        old_best_score = copy.deepcopy(self.best_score)\n",
    "        self._restarts = 'FINAL'\n",
    "\n",
    "        self._GuidanceSystem(self.best_combo)\n",
    "\n",
    "        while(self.best_score-old_best_score > 0):\n",
    "            old_best_score = copy.deepcopy(self.best_score)\n",
    "            self._GuidanceSystem(self.best_combo)\n",
    "\n",
    "\n",
    "\n",
    "        # Display final information\n",
    "        self.view_best_combo_and_score()\n",
    "    \n",
    "\n",
    "\n",
    "    def tune_parallel(self, part, splits, key_stats_only = False):\n",
    "        \"\"\" Begin tuning in Parallel \"\"\"\n",
    "\n",
    "        assert type(part) is int and type(splits) is int\n",
    "\n",
    "        if part <= 0 or part > splits:\n",
    "            raise ValueError(\"Part must be within [1, splits]\")\n",
    "            \n",
    "\n",
    "        if self.train_x is None or self.train_y is None or self.val_x is None or self.val_y is None or self.test_x is None or self.test_y is None:\n",
    "            raise AttributeError(\" Missing one of the datasets, please run .read_in_data() \")\n",
    "            \n",
    "\n",
    "        if self.model is None:\n",
    "            raise AttributeError(\" Missing model, please run .read_in_model() \")\n",
    "            \n",
    "\n",
    "        if self.tuning_result_saving_address is None:\n",
    "            raise AttributeError(\"Missing tuning result csv saving address, please run .set_tuning_result_saving_address() first\")\n",
    "\n",
    "\n",
    "        self.key_stats_only = key_stats_only\n",
    "\n",
    "        print(\"BEGIN TUNING\\n\\n\") \n",
    "        \n",
    "        # FIRST: get all cruise combinations as well as core, and tune all these\n",
    "        self._get_core()\n",
    "        self._get_cruise_combinations() \n",
    "\n",
    "        first_round_combinations = copy.deepcopy(self._cruise_combinations)\n",
    "        first_round_combinations.append(self._core) \n",
    "\n",
    "        random.seed(self._seed)\n",
    "        random.shuffle(first_round_combinations)\n",
    "\n",
    "        parallel_combo_to_tune = copy.deepcopy(first_round_combinations)\n",
    "        start_index = int((part-1)/splits * len(first_round_combinations))\n",
    "        end_index = int(part/splits * len(first_round_combinations))\n",
    "        parallel_combo_to_tune = parallel_combo_to_tune[start_index:end_index]\n",
    "\n",
    "        print(f'Parallel tuning part {part} of Cruise: set to tune {len(parallel_combo_to_tune)} combinations')\n",
    "\n",
    "        print(\"STAGE ZERO: Tune all Cruise combinations\\n\\n\")\n",
    "        for combo in parallel_combo_to_tune:\n",
    "            \n",
    "            if not self.checked[tuple(combo)]:\n",
    "                self._up_to += 1\n",
    "                self._train_and_test_combo(combo)\n",
    "            \n",
    "            else:\n",
    "                self._check_already_trained_best_score(combo)\n",
    "\n",
    "\n",
    "        # Display final information\n",
    "        self.view_best_combo_and_score()\n",
    "\n",
    "\n",
    "\n",
    "    def _eval_combo(self, df_building_dict, train_pred, val_pred, test_pred):\n",
    "\n",
    "        if self.clf_type == 'Regression':\n",
    "\n",
    "            train_score = val_score = test_score = train_rmse = val_rmse = test_rmse = train_mape = val_mape = test_mape = 0\n",
    "\n",
    "            try:\n",
    "                train_score = r2_score(self.train_y, train_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_score = r2_score(self.val_y, val_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_score = r2_score(self.test_y, test_pred)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                train_rmse = np.sqrt(mean_squared_error(self.train_y, train_pred))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_rmse = np.sqrt(mean_squared_error(self.val_y, val_pred))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_rmse = np.sqrt(mean_squared_error(self.test_y, test_pred))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if self.key_stats_only == False:\n",
    "                try:\n",
    "                    train_mape = mean_absolute_percentage_error(self.train_y, train_pred)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    val_mape = mean_absolute_percentage_error(self.val_y, val_pred)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    test_mape = mean_absolute_percentage_error(self.test_y, test_pred)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            df_building_dict['Train r2'] = [np.round(train_score, 6)]\n",
    "            df_building_dict['Val r2'] = [np.round(val_score, 6)]\n",
    "            df_building_dict['Test r2'] = [np.round(test_score, 6)]\n",
    "            df_building_dict['Train RMSE'] = [np.round(train_rmse, 6)]\n",
    "            df_building_dict['Val RMSE'] = [np.round(val_rmse, 6)]\n",
    "            df_building_dict['Test RMSE'] = [np.round(test_rmse, 6)]\n",
    "            \n",
    "            if self.key_stats_only == False:\n",
    "                df_building_dict['Train MAPE'] = [np.round(train_mape, 6)]\n",
    "                df_building_dict['Val MAPE'] = [np.round(val_mape, 6)]\n",
    "                df_building_dict['Test MAPE'] = [np.round(test_mape, 6)]\n",
    "\n",
    "        \n",
    "        elif self.clf_type == 'Classification':\n",
    "\n",
    "            train_score = val_score = test_score = train_bal_accu = val_bal_accu = test_bal_accu = train_f1 = val_f1 = test_f1 = \\\n",
    "                train_precision = val_precision = test_precision = train_recall = val_recall = test_recall = 0\n",
    "\n",
    "            try:    \n",
    "                train_score = accuracy_score(self.train_y, train_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_score = accuracy_score(self.val_y, val_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_score = accuracy_score(self.test_y, test_pred)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                train_bal_accu = balanced_accuracy_score(self.train_y, train_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_bal_accu = balanced_accuracy_score(self.val_y, val_pred)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_bal_accu = balanced_accuracy_score(self.test_y, test_pred)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                train_f1 = f1_score(self.train_y, train_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_f1 = f1_score(self.val_y, val_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_f1 = f1_score(self.test_y, test_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                train_precision = precision_score(self.train_y, train_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_precision = precision_score(self.val_y, val_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_precision = precision_score(self.test_y, test_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                train_recall = recall_score(self.train_y, train_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                val_recall = recall_score(self.val_y, val_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                test_recall = recall_score(self.test_y, test_pred, average='weighted')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            df_building_dict['Train accu'] = [np.round(train_score, 6)]\n",
    "            df_building_dict['Val accu'] = [np.round(val_score, 6)]\n",
    "            df_building_dict['Test accu'] = [np.round(test_score, 6)]\n",
    "            df_building_dict['Train balanced_accuracy'] = [np.round(train_bal_accu, 6)]\n",
    "            df_building_dict['Val balanced_accuracy'] = [np.round(val_bal_accu, 6)]\n",
    "            df_building_dict['Test balanced_accuracy'] = [np.round(test_bal_accu, 6)]\n",
    "            df_building_dict['Train f1'] = [np.round(train_f1, 6)]\n",
    "            df_building_dict['Val f1'] = [np.round(val_f1, 6)]\n",
    "            df_building_dict['Test f1'] = [np.round(test_f1, 6)]\n",
    "            df_building_dict['Train precision'] = [np.round(train_precision, 6)]\n",
    "            df_building_dict['Val precision'] = [np.round(val_precision, 6)]\n",
    "            df_building_dict['Test precision'] = [np.round(test_precision, 6)]\n",
    "            df_building_dict['Train recall'] = [np.round(train_recall, 6)]\n",
    "            df_building_dict['Val recall'] = [np.round(val_recall, 6)]\n",
    "            df_building_dict['Test recall'] = [np.round(test_recall, 6)]\n",
    "\n",
    "        return df_building_dict, val_score, test_score\n",
    "    \n",
    "\n",
    "\n",
    "    def _train_and_test_combo(self, combo):\n",
    "        \"\"\" Helper to train and test each combination as part of tune() \"\"\"\n",
    "\n",
    "        combo = tuple(combo)\n",
    "        \n",
    "        params = {self.hyperparameters[i]:self.parameter_choices[self.hyperparameters[i]][combo[i]] for i in range(len(self.hyperparameters))}\n",
    "        \n",
    "        \n",
    "        # initialise object\n",
    "        clf = self.model(**params)\n",
    "\n",
    "        start = time.time()\n",
    "        val_score = clf.predict(self.data, 500)\n",
    "        test_score = clf.predict(self.data, 250)\n",
    "\n",
    "        CV_score_list = [val_score]\n",
    "        for day in [100, 200, 300, 400]:  \n",
    "            CV_score_list.append(clf.predict(self.data, day)) \n",
    "        CV_score = np.mean(CV_score_list)     \n",
    "        end = time.time()\n",
    "\n",
    "        # build output dictionary and save result\n",
    "        df_building_dict = params\n",
    "        df_building_dict['Val r2'] = [val_score]\n",
    "        df_building_dict['Test r2'] = [test_score]\n",
    "        df_building_dict['CV r2'] = [CV_score]\n",
    "\n",
    "\n",
    "        tmp = pd.DataFrame(df_building_dict)\n",
    "\n",
    "\n",
    "        self.tuning_result = pd.concat([self.tuning_result, tmp])\n",
    "        self.tuning_result.index = range(len(self.tuning_result))\n",
    "        self._save_tuning_result()\n",
    "\n",
    "        # update best score stats\n",
    "        if val_score > self.best_score: \n",
    "            self.best_score = val_score\n",
    "            self.best_clf = clf\n",
    "            self.best_combo = combo\n",
    "\n",
    "        # update internal governing DataFrames\n",
    "        self.checked[combo] = 1\n",
    "        self.result[combo] = val_score\n",
    "\n",
    "        self._up_to += 1\n",
    "\n",
    "        print(f'''Trained and Tested combination {self._up_to} of {self._total_combos}: {combo}, taking time {np.round(end-start, 4)} seconds to get score of {np.round(val_score,4)}\n",
    "        Current best combo: {self.best_combo} with val score {np.round(self.best_score, 4)}''')\n",
    "\n",
    "\n",
    "\n",
    "    def _check_already_trained_best_score(self, combo):\n",
    "        \"\"\" Helper for checking whether an already trained combo is best score \"\"\"\n",
    "        \n",
    "        combo = tuple(combo)\n",
    "        \n",
    "        # update best score stats\n",
    "        if self.result[combo] > self.best_score: \n",
    "            self.best_score = self.result[combo]\n",
    "            self.best_clf = None\n",
    "            print(f\"As new Best Combo {combo} was read in, best_clf is set to None\")\n",
    "            self.best_combo = combo\n",
    "\n",
    "        print(f'''Already Trained and Tested combination {combo}, which had val score of {np.round(self.result[combo],4)}\n",
    "        Current best combo: {self.best_combo} with val score {np.round(self.best_score, 4)}. \n",
    "        Has trained {self._up_to} of {self._total_combos} combinations so far''')\n",
    "\n",
    "\n",
    "\n",
    "    def _save_tuning_result(self):\n",
    "        \"\"\" Helper to export tuning result csv \"\"\"\n",
    "\n",
    "        tuning_result_saving_address_split = self.tuning_result_saving_address.split('.csv')[0]\n",
    "\n",
    "        self.tuning_result.to_csv(f'{tuning_result_saving_address_split}.csv', index=False)\n",
    "\n",
    "    \n",
    "\n",
    "    def view_best_combo_and_score(self):\n",
    "        \"\"\" View best combination and its validation score \"\"\"\n",
    "        \n",
    "        print('Max Score: \\n', self.best_score)\n",
    "\n",
    "        if self.clf_type == 'Classification':\n",
    "            max_val_id = self.tuning_result['Val accu'].idxmax()\n",
    "            print('Max Test Score: \\n', self.tuning_result.iloc[max_val_id]['Test accu'])\n",
    "            \n",
    "        elif self.clf_type == 'Regression':\n",
    "            max_val_id = self.tuning_result['Val r2'].idxmax()\n",
    "            print('Max Test Score: \\n', self.tuning_result.iloc[max_val_id]['Test r2'])\n",
    "\n",
    "        print('Max Combo Index: \\n', self.best_combo, 'out of', self.n_items, '(note best combo is 0-indexed)')\n",
    "\n",
    "        final_combo = {self.hyperparameters[i]:self.parameter_choices[self.hyperparameters[i]][self.best_combo[i]] for i in range(len(self.hyperparameters))}\n",
    "        print('Max Combo Hyperparamer Combination: \\n', final_combo)\n",
    "\n",
    "        if self._tune_features:\n",
    "            print('Max Combo Features: \\n', self._feature_combo_n_index_map[self.best_combo[-1]])\n",
    "\n",
    "        print('% Combos Checked:', int(sum(self.checked.reshape((np.prod(self.n_items))))), 'out of', np.prod(self.n_items), 'which is', f'{np.mean(self.checked).round(8)*100}%')\n",
    "\n",
    "\n",
    "\n",
    "    def read_in_tuning_result_df(self, address): \n",
    "        \"\"\" Read in tuning result csv and read data into checked and result arrays \"\"\"\n",
    "\n",
    "        BOOL_MAP = {'1': True, '0': False, '1.0': True, '0.0': False, True: True, False: False, 'True': True, 'False': False, 1: True, 0: False, 1.0: True, 0.0: False}\n",
    "\n",
    "        if self.parameter_choices is None:\n",
    "            raise AttributeError(\"Missing parameter_choices to build _parameter_value_map_index, please run set_hyperparameters() first\")\n",
    "\n",
    "        if self.clf_type is None:\n",
    "            raise AttributeError('Missing clf_type. Please run .read_in_model() first.')\n",
    "\n",
    "        self.tuning_result = pd.read_csv(address)\n",
    "\n",
    "        self._up_to = 0\n",
    "\n",
    "        self._create_parameter_value_map_index()\n",
    "\n",
    "        # read DataFrame data into internal governing DataFrames of JiaoCheng\n",
    "        for row in self.tuning_result.iterrows():\n",
    "\n",
    "            try:\n",
    "                self._up_to += 1\n",
    "        \n",
    "                combo = list()\n",
    "                for hyperparam in self.hyperparameters:\n",
    "                    if hyperparam == 'features':\n",
    "                        \n",
    "                        # reverse two dicts\n",
    "                        index_n_feature_combo_map = {self._feature_combo_n_index_map[key]:key for key in self._feature_combo_n_index_map}\n",
    "                        # special input\n",
    "                        combo.append(index_n_feature_combo_map[tuple(self._str_to_list(row[1]['features']))])\n",
    "                        \n",
    "                    else:\n",
    "                        if type(self.parameter_choices[hyperparam][0]) is bool:\n",
    "                            combo.append(self._parameter_value_map_index[hyperparam][BOOL_MAP[row[1][hyperparam]]])\n",
    "                        else:\n",
    "                            combo.append(self._parameter_value_map_index[hyperparam][row[1][hyperparam]])\n",
    "\n",
    "                combo = tuple(combo)\n",
    "                \n",
    "                self.checked[combo] = 1\n",
    "                \n",
    "                if self.clf_type == 'Regression':\n",
    "                    self.result[combo] = row[1]['Val r2']\n",
    "                elif self.clf_type == 'Classification':\n",
    "                    self.result[combo] = row[1]['Val accu']\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error message: {str(e)}\")\n",
    "                print('Error Importing this Row:', row)\n",
    "\n",
    "        print(f\"Successfully read in tuning result of {len(self.tuning_result)} rows\")\n",
    "\n",
    "\n",
    "\n",
    "    def _str_to_list(self, string):\n",
    "        \"\"\" Helper to convert string to list\"\"\"\n",
    "\n",
    "        out = list()\n",
    "        for feature in string.split(', '):\n",
    "            out.append(feature.strip('[').strip(']').strip(\"'\"))\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "    \n",
    "    def _create_parameter_value_map_index(self):\n",
    "        \"\"\" Helper to create parameter-value index map \"\"\"\n",
    "\n",
    "        self._parameter_value_map_index = dict()\n",
    "        for key in self.parameter_choices.keys():\n",
    "            tmp = dict()\n",
    "            for i in range(len(self.parameter_choices[key])):\n",
    "                tmp[self.parameter_choices[key][i]] = i\n",
    "            self._parameter_value_map_index[key] = tmp\n",
    "\n",
    "\n",
    "    \n",
    "    def set_tuning_result_saving_address(self, address):\n",
    "        \"\"\" Read in where to save tuning object \"\"\"\n",
    "\n",
    "        self.tuning_result_saving_address = address\n",
    "        print('Successfully set tuning output address')\n",
    "\n",
    "\n",
    "\n",
    "    def set_best_model_saving_address(self, address):\n",
    "        \"\"\" Read in where to save best model  \"\"\"\n",
    "\n",
    "        self.best_model_saving_address = address\n",
    "        print('Successfully set best model output address')\n",
    "\n",
    "    \n",
    "\n",
    "    def _save_best_model(self):\n",
    "        \"\"\" Helper to save best model as a pickle \"\"\"\n",
    "\n",
    "        best_model_saving_address_split = self.best_model_saving_address.split('.pickle')[0]\n",
    "\n",
    "        with open(f'{best_model_saving_address_split}.pickle', 'wb') as f:\n",
    "            pickle.dump(self.best_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YangZhouB Initialised\n",
      "Successfully read in model <class '__main__.TradingStrategy'>, which is a Regression model\n",
      "Successfully recorded hyperparameter choices\n",
      "Successfully set tuning output address\n"
     ]
    }
   ],
   "source": [
    "tuner = YangZhouB()\n",
    "tuner.read_in_data(data)\n",
    "tuner.read_in_model(TradingStrategy, 'Regression')\n",
    "\n",
    "parameter_choices = {\n",
    "    'short_term': (2, 3, 4, 5, 6, 7, 8, 9, 10),\n",
    "    'long_term': (15, 20, 25, 30, 35, 40, 45, 50),\n",
    "    'price_range': (3, 4, 5, 6, 8, 7, 8, 9, 10),\n",
    "    'amp_window': (25, 50, 75, 100, 125, 150),\n",
    "    'increase_holding': (250, 500, 1000, 1500, 2000, 4000),\n",
    "    'decrease_holding': (250, 500, 1000, 1500, 2000, 4000),\n",
    "    'amp_lo_threshold': (5, 7.5, 10, 12.5, 15),\n",
    "    'amp_hi_threshold': (0.5, 1, 1.5, 2, 2.5, 3),\n",
    "    'mse_threshold': (0.005, 0.01, 0.02, 0.04),\n",
    "}\n",
    "\n",
    "tuner.set_hyperparameters(parameter_choices)\n",
    "tuner.set_tuning_result_saving_address('./tuning/TradingStrategy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN TUNING\n",
      "\n",
      "\n",
      "STAGE ZERO: Tune all Cruise combinations\n",
      "\n",
      "\n",
      "Trained and Tested combination 2 of 16796160: (4, 7, 4, 5, 0, 0, 4, 0, 3), taking time 63.5824 seconds to get score of -1.884\n",
      "        Current best combo: (4, 7, 4, 5, 0, 0, 4, 0, 3) with val score -1.884\n"
     ]
    }
   ],
   "source": [
    "tuner.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
